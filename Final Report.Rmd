---
title: "Final Report"
author: "王力为 19020152203156"
date: "2018年6月3日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# 研究背景

单细胞RNA-seq数据可以通过单细胞水平上基因表达的分子表征来洞察正常的细胞功能和各种疾病状态。单细胞RNA表达分析（scRNA-seq）正在彻底改变整个生物体科学[1,2]，可以在细胞水平上无偏地识别先前未鉴定过的分子异质性，提供了解剖复杂组织和特定细胞环境组成的手段。

本次实验单细胞测序的基因表达数据，420个细胞是单细胞，共16000个基因。402个非正常实验组CLP，18个正常组，sham。

1，这是一个非常非常非平衡数据+超级高维数据的问题，并且小样本——业界难题

2，有监督，分类问题。分类首先是二分类，其次还潜在为多分类问题

3，同时需要有较强大的生物学背景知识支持

4，目的不仅要成功分类（减轻人工压力），还要可解释，即找到因子变量，可能还要确定分类阈值！

问题背景：引用胡杰老师的method文件夹。单细胞测序是干嘛，会遇到什么问题，有什么好的方法。见最后总结（不仅仅是非平衡）

# 研究背景曾老师介绍

1. 关于单细胞分类的。国内就很火

2.以前的技术没有办法单个细胞，bulk测序，所有细胞都混在一块测，传统测序，认为所有细胞都是一样的

3.但现在技术可以了。关键在于怎么分离细胞，如荧光去挑。或者单个芯片类似于管道之类的。

4.它的意义就在于，每个细胞还是不太一样的，同种细胞也会表现出不一样（如都是T细胞，且即便再细分，也不够细分，还有很多小类）。所以单细胞技术可以看到细胞多样性——如细胞发育（同一个祖宗来的）。也可以由这个多样性进一步更好确定某些显著的基因

但这个是优点也是缺点，我们在数据上就会产生非常难办的特征。下面会说到

########

实验主角是中性粒细胞。中性粒细胞有很多阶段，如成熟或不成熟（成熟没有分化能力有杀菌能力）。同样是成熟或不成熟的细胞是也不一样的。比如在本次实验里的某种感染后，成熟的都不见了，多出来的是不成熟的，而且还和传统不成熟的不一样——这是为啥？？？我们感兴趣的就是这一部分未成熟细胞，和未感染前传统的未成熟细胞的区别。背后的区别就从基因来分辨

5.数据是小鼠胃溃疡，控制组（sham）和实验组（CLP）是：是否有某种感染。看对照小鼠和实验小鼠的整个机体脾脏的中性粒细胞，而且是未成熟的中性粒细胞（也就是这里的单细胞）的RNA的测序基因表达，在有无刺激下面，会不会有某些基因是显著的不同。

注：这里要注意的点是，是否感染，也就是控制实验组的0和1是确定的。但是，人为筛出来的目前所有的样本细胞的“未成熟的中性粒细胞”，①控制组和实验组的未成熟肯定是不一样的，是我们要二分类的原因。②在实验组402个未成熟的中性粒细胞中，还有可能有些未成熟的来源是不一样的，pattern不一样，因此还有可能要多分类——这个多分类应该由聚类解决（但是K非常难确定。这是日后的事情了）

6.现在是真实数据，后续也可以仿真

7.这种基因表达数据的特点

①非正态性非常强，因为现在是分离的，不再是bulk，所以量非常少，所以肯定不漂亮。

②并且因为太少了，有些测不到，所以造成零膨胀。

③第三个是由于基因数据不纯，虽然都是非成熟细胞，但不同的细胞所在的pattern可能不太一样，所以会存在多峰多模态的特点。

8.所以要用非参模型会更加有效！！！！

9.同时是非平衡的，这个不用说了。可以用真实数据做，也可以用仿真数据做。但在多重假设检验里其实影响不是很大。影响更大的是零膨胀dropout

10.那仿真技术呢，原始的bulk，分位数变换，加上其他方法可以实现

11.有些可以从降维看development，有些是发育的时间来分等（基于流形的方法）（早期分不开，stage接不上，不太好。但晚期分的比较好。找个投影）

后续：
12.多重假设检验会遇到的问题：

①非平衡，n1，n2不同，power会不同

②零膨胀，太多的零会不会对KS（已知不能用正态检验了，那就KS检验吧）造成影响

注，可以用SPLATTER方法，仿真设置missing rate；或ZINB-WAVE，仿真同一个整体不同的missing data，验证KS是否合适。不管怎么样后续再说

13.曾老师那边还用了秩相关检验的方法，是基因与基因之间的，这个还不清楚老师具体是怎么操作的。到时候可以再试一下。


# 目前的两大方向

1.针对非平衡高维二分类数据的各种机器学习方法。以下又细分成shrinkage和树方法等。选出来的基因进行探讨。遇到的问题就是非平衡和高维，还有二分类是否合适，还有就是非常多的随机种子随机因素，对最后结果造成的影响！！！

注：零膨胀和非正态并没有处理，不过AUC值已经比较高了，会不会影响、要不要处理暂时省略

2.使用多重假设检验，遇到的问题就是非正态、非平衡和零膨胀。用KS非参的方法一个个试，0太多的基因直接去掉。

*3.sc3等方法的聚类，多分类问题（这个最后再解决吧，慢慢来）

*4.老师那边的秩相关检验的方法，还不知道怎么实施

# 载入包
```{r}
library(glmnet)
library(ncvreg)
library(MASS)
#library(bigRR)
library(parallel)
library(caret)
library(pROC)
library(kernlab)
library(ROCR)
library(grplasso)

library(Rtsne)
library(rgl)
library(scatterplot3d)

library(adabag)
library(rpart)
library(tree)
library(e1071)
library(randomForest)

library(DMwR)

```


# 导入数据
```{r,cache=T }
rawdata<-readRDS("C:\\Users\\Haha\\Desktop\\单细胞测序\\immature_neutrophil.rds")
condition<-rawdata[['condition']]
condition<-data.frame(condition)
data<-data.frame(rawdata[['data']])
data<-data.frame(t(data))
condition<-condition$condition
data<-cbind(condition,data)
data[1:5,1:5]

###########
#Sum<-apply(data[,-1], 1, sum)
#Mean<-apply(data[,-1], 1, mean)
#Std<-apply(data[,-1], 1, sd)
#Median<-apply(data[,-1], 1, median)
#datadiscribe<-cbind(data,Sum,Mean,Std,Median)
#head(datadiscribe[,(ncol(datadiscribe)-3):ncol(datadiscribe)])

#######
#sum(datadiscribe$condition=='sham')
#sum(datadiscribe$condition=='CLP')

#boxplot(Sum~condition,col=c(2:6))
#boxplot(Mean~condition,col=c(2:6))
#boxplot(Std~condition,col=c(2:6))
#看不出什么差别

#plot(Mean,Std,pch=20,col=factor(condition),lty=1,lwd=1)
#红点为sham，对照组（正常的表达），18个，非平衡
#这样子看实在是太太非平衡了

##############缺失值

#hang<-which(rowSums(is.na(data)) > 0)
#hang#没有缺失值！！


```

# 方向一：非平衡高维分类问题方向

## 数据预处理

为防止数据随机性，本文所有种子都设置为1

```{r,cache=T }
#################
#准备工作，拆分成训练集和测试集
set.seed(1)
Y<-data$condition
Ytestnum<-c(sample(which(Y=='sham'),length(which(Y=='sham'))/3,replace = F),sample(which(Y=='CLP'),length(which(Y=='CLP'))/3,replace = F))
Ytestnum<-sample(Ytestnum,length(Ytestnum),replace = F)
Ytest<-Y[Ytestnum]#三分之一分给测试集，三分之二为训练集.
Ytrain<-Y[-Ytestnum]
Y01<-rep(1,length(Y))
Y01[Y=='sham']<-0
Ytrain01<-rep(1,length(Ytrain))
Ytrain01[Ytrain=='sham']<-0 #sham的，即正常的，取0，为非常少的部分
Ytest01<-rep(1,length(Ytest))
Ytest01[Ytest=='sham']<-0
length(Ytest01)

XXX<-as.matrix(data[,2:ncol(data)])
#然后取出一整列都是0的列
XX<-XXX[,-which(apply(abs(XXX),2,sum)==0)]
dim(XX)
length0<-function(X){
  return(sum(X!=0))#n=402减去0的个数，为非0的个数，如第一列在训练集中，只有8个非0
}
X<-XX[,which(apply(XX[which(Y=='CLP'),],2,length0)>=0.05*402)]#非0元素个数小于20的列,直接删掉
dim(X)


Xtest<-X[Ytestnum,]
Xtrain<-X[-Ytestnum,] 
dim(Xtrain)

Xscale<-scale(X)
Xtestscale<-Xscale[Ytestnum,]
Xtrainscale<-Xscale[-Ytestnum,] 
dim(Xtrainscale)


```

三分之一分给测试集，三分之二为训练集，即280:140.
402：18，
测试集的小样本只有6个


## PCA和TSNE非线性降维，初见数据

### TSNE

```{r,cache=T}

color<-rep('black', length(Y))
color[which(Y=='sham')]<-'green'#绿色是sham！！！！！！！！！！！！

set.seed(1)
tsne2<-Rtsne(X,dims = 2)
plot(tsne2$Y[,1],tsne2$Y[,2],main='TSNE',col=color,pch=20)

set.seed(1)
tsne3<-Rtsne(X,dims = 3,perplexity = 30,verbose = F,max_iter = 1000)
scatterplot3d(tsne3$Y[,1],tsne3$Y[,2],tsne3$Y[,3],color=color,
              highlight.3d=F,pch = 20,angle=80,main='TSNE',
              type = 'p',grid = F,col.grid = "lightblue",col.axis = 'lightblue',col.lab = T,scale.y =2,xlim = c(-20,20),ylim = c(-25,25),zlim = c(-30,30))

```

并没有多大区别，分的很零散，并不能给出什么建议

### PCA



## Shrinkage,各种LASSO的思路,解决高维建模问题

（1）不用STEP是因为维度太大，STEP极易陷入局部最优解

（2）不用主成分降维是因为要具体到某一个基因，所以主成分出来的意义不大。当然除非有非常强的生物学解释意义，不排除这种做法。可后续尝试。

### SCAD
```{r,cache=T }
#然后scad
set.seed(1)
scad.mod<-cv.ncvreg(Xtrainscale,Ytrain01,family='binomial',penalty='SCAD')
#plot(scad.mod)
coeffscad<-coef(scad.mod)

#如果用SCAD的话，提取出不为0的自变量——貌似系数都是负数
sum(coeffscad[-1]!=0)
sum(coeffscad[-1]==0)
sort(abs(coeffscad[which(coeffscad[-1]!=0)+1]),decreasing = T)
class(coeffscad)
#共有9个，有正有负。最重要的由系数的绝对值大小决定

#Calr        Gzma        Ccl5       Hspa5       Snx19        Eif1 
# Axin1      Nt5c3      Hacd4

pred.scad<-predict(scad.mod,Xtrainscale,type='response',family='binomial')
pred.scad2<-prediction(pred.scad,Ytrain01)

#这是已经找到最优阈值的一种简便方法，阈值不再是0.5
#如果要看阈值为0.5的话...基本上都是0

perfscad<-performance(pred.scad2,'sens','spec')
#perfscad@x.values#specificity
#perfscad@y.values#TPR
performance(pred.scad2,'auc')@y.values#0.97

pred.scad<-predict(scad.mod,Xtestscale,type='response',family='binomial')
pred.scad2<-prediction(pred.scad,Ytest01)

#这是已经找到最优阈值的一种简便方法，阈值不再是0.5
#如果要看阈值为0.5的话...基本上都是0

perfscad<-performance(pred.scad2,'sens','spec')
#perfscad@x.values#specificity
#perfscad@y.values#TPR
performance(pred.scad2,'auc')@y.values#0.91


auc.scad<-roc(Ytest01,pred.scad)
print(auc.scad)
plot(auc.scad,ylim=c(0,1),print.thres=T,main=paste('AUC.SCAD',round(auc.scad$auc[[1]],2)))

#阈值为0.957，什么意思？即大于这个值才为1，CLP病变
```
AUC达到0.91,对应的sensitivity（TPR）和specificity（1-FPR）。最优阈值为0.957。都如图。


### ridge+adaptiveLasso
```{r,cache=T}
#然后ridge+adaptiveLasso

set.seed(1)
ridge.mod2<-cv.glmnet(Xtrainscale,Ytrain01,alpha=0,family='binomial',type.measure = 'auc')
coeffridge<-coef(ridge.mod2)
w<-1/abs(coeffridge[-1])
adalasso.mod<-cv.glmnet(Xtrainscale,Ytrain01,alpha=1,penalty.factor=w,family='binomial',type.measure = 'auc')
coeffada2<-coef(adalasso.mod)
length(w)

sum(coeffada2[-1]!=0)
which(coeffada2[-1]!=0)
sum(coeffada2[-1]==0)
order(abs(coeffada2[coeffada2!=0]),decreasing = T)
coeffada2@Dimnames[[1]][order(abs(coeffada2[coeffada2!=0]),decreasing = T)]
class(coeffada2)

#"X0610009B22Rik" "X0610037L13Rik" "X0610009O20Rik" "X0610012G03Rik"
#"X1110004F10Rik" "X0610030E20Rik" "X0610007P14Rik" "X0610010K14Rik"

#######
#但是没有任何同样出现的基因？
##########

pred.ada<-predict(adalasso.mod,Xtrainscale,type='response',family='binomial')
pred.ada2<-prediction(pred.ada,Ytrain01)
perfada<-performance(pred.ada2,'sens','spec')
#perfada@x.values#specificity
#perfada@y.values#TPR
performance(pred.ada2,'auc')@y.values#0.96

pred.ada<-predict(adalasso.mod,Xtestscale,type='response',family='binomial')
pred.ada2<-prediction(pred.ada,Ytest01)
perfada<-performance(pred.ada2,'sens','spec')
#perfada@x.values#specificity
#perfada@y.values#TPR
performance(pred.ada2,'auc')@y.values#0.91

auc.ada<-roc(Ytest01,pred.ada)
print(auc.ada)
plot(auc.ada,ylim=c(0,1),print.thres=T,main=paste('AUC.ADA',round(auc.ada$auc[[1]],3)))
#阈值为0.959
```
### elastic net
```{r,cache=T}
#然后elastic net

set.seed(1)
elastic.mod<-cv.glmnet(Xtrainscale,Ytrain01,maxit=1000000,alpha=0.8,penalty.factor=w,family='binomial',type.measure = 'auc')
coeffela<-coef(elastic.mod)
sum(coeffela[-1]!=0)
which(coeffela[-1]!=0)
sum(coeffela[-1]==0)
order(abs(coeffela[coeffela!=0]),decreasing = T)
coeffela@Dimnames[[1]][order(abs(coeffela[coeffela!=0]),decreasing = T)]
#每次超参都不稳定，自变量也不稳定。所以设立种子

#"X0610009B22Rik" "X1110004F10Rik" "X0610009O20Rik" "X0610030E20Rik"
#"X0610007P14Rik" "X0610037L13Rik" "X0610010K14Rik" "X1110037F02Rik" "X1110012L19Rik"
#"X1110008F13Rik" "X1110008P14Rik" "X0610012G03Rik"

#######
#这下有共同点了，全部都是RIK族
##########

pred.elas<-predict(elastic.mod,Xtrainscale,type='response',family='binomial')
pred.elas2<-prediction(pred.elas,Ytrain01)
perfelas<-performance(pred.elas2,'sens','spec')
#perfelas@x.values#
#perfelas@y.values#TPR
performance(pred.elas2,'auc')@y.values#AUC达到0.99，训练集达到最佳！

pred.elas<-predict(elastic.mod,Xtestscale,type='response',family='binomial')
pred.elas2<-prediction(pred.elas,Ytest01)
perfelas<-performance(pred.elas2,'sens','spec')
#perfelas@x.values#
#perfelas@y.values#TPR
performance(pred.elas2,'auc')@y.values#AUC达到0.925,比前两个好

auc.elas<-roc(Ytest01,pred.elas)
print(auc.elas)
plot(auc.elas,ylim=c(0,1),print.thres=T,main=paste('AUC.elastic',round(auc.elas$auc[[1]],3)))
#阈值为0.031

```
### group lasso
```{r,cache=T}
##############################
#shrinkage方法最后尝试group lasso

set.seed(1)
grpfit<-grplasso(Ytrain01~., data=cbind(Ytrain01,data.frame(Xtrainscale)),model = LogReg(),lambda = 10)
coeffgrp<-coef(grpfit)
sum(coeffgrp[-1]!=0)
which(coeffgrp[-1]!=0)
sum(coeffgrp[-1]==0)
order(abs(coeffgrp[coeffgrp!=0]),decreasing = T)
coeffgrp<-data.frame(coeffgrp)
rownames(coeffgrp)[order(abs(coeffgrp[coeffgrp!=0]),decreasing = T)]

#"X0610009B22Rik" "X0610009O20Rik" "X0610012G03Rik" "X0610037L13Rik""X1110008P14Rik"
#"X0610007P14Rik" "X1110008F13Rik" "X0610010K14Rik" "X0610030E20Rik""X1110004F10Rik"

pred.grp<-predict(grpfit,Xtrainscale,type='response',family='binomial')
pred.grp<-predict(grpfit,Xtestscale,type='response',family='binomial')

auc.grp<-roc(Ytest01,pred.grp)
print(auc.grp)
plot(auc.grp,ylim=c(0,1),print.thres=T,main=paste('AUC.grp',round(auc.grp$auc[[1]],3)))
#AUC达到0.927，是目前最好
#阈值为0.961
```


## 决策树、集成方法及SVM


```{r,cache=T}

Ytrain01<-as.factor(Ytrain01)
Ytest01<-as.factor(Ytest01)
train<-cbind(Ytrain01,data.frame(Xtrain))
test<-cbind(Ytest01,data.frame(Xtest))

```
### 决策树
```{r,cache=T}
###################直接用决策树
set.seed(1)
tree.mod<-tree(Ytrain01~., data=train)
summary(tree.mod)
plot(tree.mod)
text(tree.mod,cex=0.6)

#"Calr"           "Nt5c3"          "Anxa7"          "X1600014C10Rik" "X1110004F10Rik"
#"X1810058I24Rik"

#cvtree<-cv.tree(tree.mod,FUN=prune.tree)
#plot(cvtree$size,cvtree$dev,type='b')#发现这是有问题的。。不prune

tree.pred<-predict(tree.mod,newdata=test,type = 'class')
tree.pred2<-prediction(as.numeric(tree.pred)-1,Ytest01)
perftree<-performance(tree.pred2,'sens','spec')
#perftree@x.values#speci
#perftree@y.values#sensi
performance(tree.pred2,'auc')@y.values#AUC可以到达0.5758，但也可以毫无效果0.5

auc.tree<-roc(Ytest01,as.numeric(tree.pred)-1)
print(auc.tree)
plot(auc.tree,ylim=c(0,1),print.thres=T,main=paste('AUC.tree',round(auc.tree$auc[[1]],3)))


```

决策树用于变量选择，在生物基因表达数据上拥有更加便于解释的优点。但在非平衡问题上缺点暴露地一览无遗。

### SVM
```{r,cache=T}
#################用一下SVM.

class(Ytrain01)
wts<-100/table(Ytrain01)
svmfit<-svm(Ytrain01~.,data = train, scale=F,kernel = "radial"
            ,class.weights=wts) #尝试了不同权重也没有效果
summary(svmfit)
svm.pred<-predict(svmfit,newdata = test)
length(svm.pred)
sum(as.numeric(svm.pred)-1)
svm.pred2<-prediction(as.numeric(svm.pred)-1,Ytest01)
perfsvm<-performance(svm.pred2,'sens','spec')
#perfsvm@x.values#speci
#perfsvm@y.values#sensi
performance(svm.pred2,'auc')@y.values#AUC可以到达0.5758，但也可以毫无效果0.5

```

尝试了不同权重也没有效果


### 集成算法
```{r,cache=T}
######################
#集成算法
######################

##############用Random Forest

rf <- randomForest(Ytrain01~., data=train, ntree=100, proximity=TRUE,importance=TRUE) 
sort(importance(rf,type = 2),decreasing = T)[1:20]
#print(rf)
varImpPlot(rf)

rf.pred<-predict(rf,newdata = test)
length(rf.pred)
rf.pred2<-prediction(as.numeric(rf.pred)-1,Ytest01)
perfrf<-performance(rf.pred2,'sens','spec')
#perfrf@x.values#speci
#perfrf@y.values#sensi
performance(rf.pred2,'auc')@y.values#AUC only 0.5，为啥一点用都没有？


##############用Adaboost
set.seed(1)
adaboostSig.best <- boosting(Ytrain01~.,data = train,
                     boos = FALSE, mfinal = 5, coeflearn = 'Breiman',
                     control=rpart.control(minsplit = 0,maxdepth=3))

summary(adaboostSig.best$weights)
summary(adaboostSig.best$importance)
sort(adaboostSig.best$importance,decreasing = T)[1:14]

# 共xx个不为0的 most important factors
#Fry         Pik3cb        Lilrb4a           Eml4           Gzma X1810058I24Rik       Snhg9 
#Bnip3l         Fam49b           G0s2           Ddx5          Pcbp2          Armc3

adaboost.test.pred<-predict.boosting(adaboostSig.best,newdata = test)
adaboost.test.pred2<-prediction(as.numeric(adaboost.test.pred$class),Ytest01)
perfadaboost<-performance(adaboost.test.pred2,'sens','spec')
#perfadaboost@x.values#FPR
#perfadaboost@y.values#TPR
performance(adaboost.test.pred2,'auc')@y.values#AUC可以到达0.5758，但也可以毫无效果0.5

##############用Bagging
set.seed(1)
baggingSig.best <- bagging(Ytrain01~.,data = train,
                             boos = FALSE, mfinal = 5, coeflearn = 'Breiman',
                             control=rpart.control(minsplit = 0,maxdepth=3))
#baggingSig.best$importance
baggingSig.best$class
sort(baggingSig.best$importance,decreasing = T)[1:10]


# 共10个不为0的 most important factors
# Gzma           Fcf1           Ano6           Emg1 X1600014C10Rik       Gpatch2l
# Adipor2           Aspm           Ssh2          Aifm1 

bagging.test.pred<-predict.bagging(baggingSig.best,newdata = test)
bagging.test.pred2<-prediction(as.numeric(bagging.test.pred$class),Ytest01)
perfbagging<-performance(bagging.test.pred2,'sens','spec')
#perfbagging@x.values#spec
#perfbagging@y.values#sensi
performance(bagging.test.pred2,'auc')@y.values#AUC可以到达0.5796
```

全部同理，在非平衡问题上这类方法效果都极差

总结出现的较多的基因：Rik族、Calr、Gzma、Ccl5、Hspa5、Nt5c3、Anxa7等。但由于在非平衡数据上，所以这些基因选择可靠性较差

### 注：用集成方法Importance选变量放入LR?

```{r,cache=T}
######################
#按照选出来的变量再加入到LR中？
LRRF1<-glm(Ytrain01~Gzma+Calr+Tiam2+Nt5c3+X1110004F10Rik+Zeb1+Pofut1
                    ,data=train,family = 'binomial')
summary(LRRF1)
LRRF<-step(LRRF1)
LRRF.pred<-predict(LRRF,test,type='response')
LRRF.pred2<-prediction(LRRF.pred,Ytest01)
perfLRRF<-performance(LRRF.pred2,'sens','spec')
#perfLRRF@x.values#speci
#perfLRRF@y.values#TPR
performance(LRRF.pred2,'auc')@y.values

#AUC达到0.71，这说明其实和前面的方法差别是非常大的

```

### 备注：

shrinkage+LR的效果和集成importance+LR效果差别挺大，不是一个体系的。同时后者可能是非线性的关系，不能直接放在glm

不如尝试XGBOOST非线性one hot encoding后再加入到LR的方法！

### XGBOOST 非线性变换大法



## 开始解决非平衡问题

注：按照网站https://blog.csdn.net/a358463121/article/details/52304670 的方法一个个试。还有
 https://blog.csdn.net/heyongluoyao8/article/details/49408131

 非平衡数据的分类学习是机器学习和数据挖掘中的重要问题。解决该问题最直接的方法是采用一定的方法使数据集变得平衡。目前主要针对二类分类问题，将算法扩展为能呈现多类分类形式，是未来需深入研究的问题。同时，如何区别少数类数据和噪声数据，也有待进一步研究。 

#####

首先，在非平衡问题不解决前，所有树方法、SVM方法都是不能用的。

不平衡问题，用几种方法改进：

1.（略）改进分类器：如代价敏感方法——总之采取过拟合可能性比较低的算法

2.改变样本分布，先试试简单暴力的bootstrap，和采取如过采样方法，比如SMOTE、ADASYN

3.（已做）集成学习解决？——但基学习器不能用树

4.组合方法，如SMOTE等采样（过/欠）+SVM的分类器+XGBOOST集成组合

5.（略）其他类型做法：杠杆、异常点检测，泛化能力更好，单类SVM检测（第二大类）。

6.非机器学习做法，———FDR多重假设检验的新思路（第三大类），属于接下来的做法！


详情引用——胡杰老师的Imblanced文件夹

这里我们主要使用的是SMOTE采样方法：

### SMOTE+预处理
```{r,cache=T}

#################
#SMOTE
#################

dataSMOTE<-train
class(dataSMOTE$Ytrain01)
table(dataSMOTE$Ytrain01)
dim(dataSMOTE)

## now using SMOTE to create a more "balanced problem"
set.seed(1)
dataSMOTE1 <- SMOTE(Ytrain01 ~ ., dataSMOTE,perc.over = 1900,perc.under = 105,k=5)

table(dataSMOTE1$Ytrain01)
dim(dataSMOTE1)#过采样后，变成了479个数！


#################
#准备工作
set.seed(1)
YSMOTE<-dataSMOTE1$Ytrain01
Y01.SMOTE<-rep(0,length(YSMOTE))
Y01.SMOTE[YSMOTE=='1']<-1


XX.SMOTE<-dataSMOTE1[,2:ncol(dataSMOTE1)]
length00<-function(X){
  return(sum(X!=0))#n=479减去0的个数
}
X.SMOTE<-XX.SMOTE[,which(apply(XX.SMOTE,2,length00)>=0.05*479)]
dim(X.SMOTE)

Xscale.SMOTE<-scale(X.SMOTE)
testnum.smote<-sample(1:479,120,replace = F)

Ytrain01.SMOTE<-Y01.SMOTE[-testnum.smote]
Ytest01.SMOTE<-Y01.SMOTE[testnum.smote]
Xtest.SMOTE<-X.SMOTE[testnum.smote,]
Xtrain.SMOTE<-X.SMOTE[-testnum.smote,]
Xtestscale.SMOTE<-Xscale.SMOTE[testnum.smote,]
Xtrainscale.SMOTE<-Xscale.SMOTE[-testnum.smote,]

```
SMOTE过后，原始数据变成了239:240，总共约等于480个数.以此基础120个为测试集，359为训练集划分。


SMOTE函数参数可以解释一下： https://blog.csdn.net/jiabiao1602/article/details/42392377?locationNum=1&fps=1

问题在于SMOTE后是不是iid的？这里姑且认为是

### TSNE+PCA继续看一遍数据

```{r,cache=T}

#########SMOTE后的数据
color.SMOTE<-rep('black', length(YSMOTE))
color.SMOTE[which(YSMOTE=='0')]<-'green' #绿色是sham!!!!!!!!!!
set.seed(1)
tsne2<-Rtsne(X,dims = 2)
plot(tsne2$Y[,1],tsne2$Y[,2],main='TSNE',col=color.SMOTE,pch=20)
set.seed(1)
tsne.SMOTE<-Rtsne(X.SMOTE,dims = 3,perplexity = 30,check_duplicates = FALSE,verbose=F,max_iter=1000)
scatterplot3d(tsne.SMOTE$Y[,1],tsne.SMOTE$Y[,2],tsne.SMOTE$Y[,3],color=color.SMOTE,
             highlight.3d=F,pch = 20,angle=80,main='TSNE',
              type = 'p',grid = F,col.grid = "lightblue",col.axis = 'lightblue',col.lab = T,
              scale.y =2,xlim = c(-20,20),ylim = c(-25,25),zlim = c(-30,30))

#比较一下原来的
set.seed(1)
tsne3<-Rtsne(X,dims = 3,perplexity = 30,verbose = F,max_iter = 1000)
scatterplot3d(tsne3$Y[,1],tsne3$Y[,2],tsne3$Y[,3],color=color,
              highlight.3d=F,pch = 20,angle=80,main='TSNE',
              type = 'p',grid = F,col.grid = "lightblue",col.axis = 'lightblue',col.lab = T,scale.y =2,xlim = c(-20,20),ylim = c(-25,25),zlim = c(-30,30))


## PCA 也看一下



```

问题在于，为何TSNE里绿色———原来的sham，现在分组那么开？难道不应该是CLP有很多类别吗？

注：这里尽量标注出原始sham数据为另一个颜色。看看他们的分布

人工分为sham的部分究竟对不对呢？从TSNE来看，此假设存疑。（此问题解决√，但是CLP分的不开的确也是个问题）

### 之前的分类方法再全部丢进来

```{r,cache=T}
#1.elastic net

set.seed(1)
ridge.mod2.SMOTE<-cv.glmnet(Xtrainscale.SMOTE,Ytrain01.SMOTE,alpha=0,family='binomial',type.measure = 'auc')
w.SMOTE<-1/abs(coef(ridge.mod2.SMOTE)[-1])
elastic.mod.SMOTE<-cv.glmnet(Xtrainscale.SMOTE,Ytrain01.SMOTE,alpha=0.8,penalty.factor=w.SMOTE,family='binomial',type.measure = 'auc')
coeffela.SMOTE<-coef(elastic.mod.SMOTE)
sum(coeffela.SMOTE[-1]!=0)
which(coeffela.SMOTE[-1]!=0)
sum(coeffela.SMOTE[-1]==0)
order(abs(coeffela.SMOTE[coeffela.SMOTE!=0]),decreasing = T)
coeffela.SMOTE@Dimnames[[1]][order(abs(coeffela.SMOTE[coeffela.SMOTE!=0]),decreasing = T)]

pred.elas.SMOTE<-predict(elastic.mod.SMOTE,Xtrainscale.SMOTE,type='response',family='binomial')
pred.elas2.SMOTE<-prediction(pred.elas.SMOTE,Ytrain01.SMOTE)
perfelas.SMOTE<-performance(pred.elas2.SMOTE,'sens','spec')
#perfelas.SMOTE@x.values#
#perfelas.SMOTE@y.values#TPR
performance(pred.elas2.SMOTE,'auc')@y.values#训练集的AUC达到了1

pred.elas.SMOTE<-predict(elastic.mod.SMOTE,Xtestscale.SMOTE,type='response',family='binomial')
pred.elas2.SMOTE<-prediction(pred.elas.SMOTE,Ytest01.SMOTE)
perfelas.SMOTE<-performance(pred.elas2.SMOTE,'sens','spec')
#perfelas.SMOTE@x.values#
#perfelas.SMOTE@y.values#TPR
performance(pred.elas2.SMOTE,'auc')@y.values#满分！0.99！！！！！！！！！！

auc.elas.SMOTE<-roc(Ytest01.SMOTE,pred.elas.SMOTE)
print(auc.elas.SMOTE)
plot(auc.elas.SMOTE,ylim=c(0,1),print.thres=T,main=paste('AUC.ELAS.SMOTE',round(auc.elas.SMOTE$auc[[1]],3)))


#2.SCAD
set.seed(1)
scad.mod.SMOTE<-cv.ncvreg(Xtrainscale.SMOTE,Ytrain01.SMOTE,family='binomial',penalty='SCAD')
coeffscad.SMOTE<-coef(scad.mod.SMOTE)

sum(coeffscad.SMOTE[-1]!=0)
sum(coeffscad.SMOTE[-1]==0)
sort(abs(coeffscad.SMOTE[which(coeffscad.SMOTE[-1]!=0)+1]),decreasing = T)

pred.scad.SMOTE<-predict(scad.mod.SMOTE,Xtrainscale.SMOTE,type='response',family='binomial')
pred.scad.SMOTE2<-prediction(pred.scad.SMOTE,Ytrain01.SMOTE)#
perfscad.SMOTE<-performance(pred.scad.SMOTE2,'sens','spec')
#perfscad.SMOTE@x.values#specificity
#perfscad.SMOTE@y.values#TPR
performance(pred.scad.SMOTE2,'auc')@y.values#1

pred.scad.SMOTE<-predict(scad.mod.SMOTE,Xtestscale.SMOTE,type='response',family='binomial')
pred.scad.SMOTE2<-prediction(pred.scad.SMOTE,Ytest01.SMOTE)#
perfscad.SMOTE<-performance(pred.scad.SMOTE2,'sens','spec')
#perfscad.SMOTE@x.values#specificity
#perfscad.SMOTE@y.values#TPR
performance(pred.scad.SMOTE2,'auc')@y.values#测试集也达到了1...

auc.scad.SMOTE<-roc(Ytest01.SMOTE,pred.scad.SMOTE)
print(auc.scad.SMOTE)
plot(auc.scad.SMOTE,ylim=c(0,1),print.thres=T,main=paste('AUC.SCAD.SMOTE',round(auc.scad.SMOTE$auc[[1]],3)))

#3.grplasso
set.seed(1)
grpfit.SMOTE<-grplasso(Ytrain01.SMOTE~., data=cbind(Ytrain01.SMOTE,data.frame(Xtrainscale.SMOTE)),model = LogReg(),lambda = 10)
coeffgrp.SMOTE<-coef(grpfit.SMOTE)
sum(coeffgrp.SMOTE[-1]!=0)
which(coeffgrp.SMOTE[-1]!=0)
sum(coeffgrp.SMOTE[-1]==0)
order(abs(coeffgrp.SMOTE[coeffgrp.SMOTE!=0]),decreasing = T)
coeffgrp.SMOTE<-data.frame(coeffgrp.SMOTE)
rownames(coeffgrp.SMOTE)[order(abs(coeffgrp.SMOTE[coeffgrp.SMOTE!=0]),decreasing = T)]

pred.grp.SMOTE<-predict(grpfit.SMOTE,Xtrainscale.SMOTE,type='response',family='binomial')
auc.grp.SMOTE<-roc(Ytrain01.SMOTE,pred.grp.SMOTE)
print(auc.grp.SMOTE)
plot(auc.grp.SMOTE,ylim=c(0,1),print.thres=T,main=paste('AUC.grp',round(auc.grp.SMOTE$auc[[1]],3)))

pred.grp.SMOTE<-predict(grpfit.SMOTE,Xtestscale.SMOTE,type='response',family='binomial')

auc.grp.SMOTE<-roc(Ytest01.SMOTE,pred.grp.SMOTE)
print(auc.grp.SMOTE)
plot(auc.grp.SMOTE,ylim=c(0,1),print.thres=T,main=paste('AUC.grp',round(auc.grp.SMOTE$auc[[1]],3)))
#group lasso满分,AUC也是1




```
总结：shrinkage方法性能有很大的提升。但鉴于之前表现也不错，所以提升空间也不是很大

### 重要注释：这里要标记出SMOTE前的原始数据的分类情况，特别是6个小样本


### Tree

```{r,cache=T}

#4.tree
#按照老师的说法，tree其实可以更好的用来判断这个机理。即发病和不发病，回归系数是没多大意义的
Ytrain01.SMOTE<-as.factor(Ytrain01.SMOTE)
Ytest01.SMOTE<-as.factor(Ytest01.SMOTE)
train.SMOTE<-cbind(Ytrain01.SMOTE,data.frame(Xtrain.SMOTE))
test.SMOTE<-cbind(Ytest01.SMOTE,data.frame(Xtest.SMOTE))

set.seed(1)
tree.mod.SMOTE<-tree(Ytrain01.SMOTE~., data=train.SMOTE)
summary(tree.mod.SMOTE)
plot(tree.mod.SMOTE)
text(tree.mod.SMOTE,cex=0.6)

#"Ndc80"          "Pramef8"        "Eif1"           "Arl6ip1"        "X0610012G03Rik"
#"X1110004F10Rik" "Orm1"   

tree.pred.SMOTE<-predict(tree.mod.SMOTE,newdata=test.SMOTE,type = 'class')
tree.pred2.SMOTE<-prediction(as.numeric(tree.pred.SMOTE)-1,Ytest01.SMOTE)
perftree.SMOTE<-performance(tree.pred2.SMOTE,'sens','spec')
#perftree.SMOTE@x.values#speci
#perftree.SMOTE@y.values#sensi
performance(tree.pred2.SMOTE,'auc')@y.values#AUC可以到达0.957!!!


#尝试不同剪枝。这里seed(1)
set.seed(1)
cvtree.SMOTE<-cv.tree(tree.mod.SMOTE,FUN=prune.tree)
plot(cvtree.SMOTE$size,cvtree.SMOTE$dev,type='b')#发现大概在6层
prunetree.SMOTE<-prune.tree(tree.mod.SMOTE,best=6)
plot(prunetree.SMOTE)
text(prunetree.SMOTE,pretty=0,cex=0.6)

prunetree.pred.SMOTE<-predict(prunetree.SMOTE,newdata=test.SMOTE,type = 'class')
prunetree.pred2.SMOTE<-prediction(as.numeric(prunetree.pred.SMOTE)-1,Ytest01.SMOTE)
perfprunetree.SMOTE<-performance(prunetree.pred2.SMOTE,'sens','spec')
#perfprunetree.SMOTE@x.values#speci
#perfprunetree.SMOTE@y.values#sensi
performance(prunetree.pred2.SMOTE,'auc')@y.values#AUC可以到达0.966!!!woc简直幸福了
summary(prunetree.SMOTE)

# "Ndc80"          "Pramef8"        "Eif1"   "X1110004F10Rik" "Orm1"        
# 这五个基因，重点去看！！


auc.tree.SMOTE<-roc(Ytest01.SMOTE,as.numeric(prunetree.pred.SMOTE)-1)
print(auc.tree.SMOTE)
plot(auc.tree.SMOTE,ylim=c(0,1),print.thres=T,main=paste('AUC.tree.SMOTE',round(auc.tree.SMOTE$auc[[1]],3)))


#尝试不同剪枝。这里seed(112233)
set.seed(112233)
cvtree.SMOTE1<-cv.tree(tree.mod.SMOTE,FUN=prune.tree)
plot(cvtree.SMOTE1$size,cvtree.SMOTE1$dev,type='b')#发现大概在7层
prunetree.SMOTE1<-prune.tree(tree.mod.SMOTE,best=7)
plot(prunetree.SMOTE1)
text(prunetree.SMOTE1,pretty=0,cex=0.6)

prunetree.pred.SMOTE1<-predict(prunetree.SMOTE1,newdata=test.SMOTE,type = 'class')
prunetree.pred2.SMOTE1<-prediction(as.numeric(prunetree.pred.SMOTE1)-1,Ytest01.SMOTE)
perfprunetree.SMOTE1<-performance(prunetree.pred2.SMOTE1,'sens','spec')
#perfprunetree.SMOTE@x.values#speci
#perfprunetree.SMOTE@y.values#sensi
performance(prunetree.pred2.SMOTE1,'auc')@y.values#AUC可以到达0.966!!!woc简直幸福了
summary(prunetree.SMOTE1)

auc.tree.SMOTE1<-roc(Ytest01.SMOTE,as.numeric(prunetree.pred.SMOTE1)-1)
print(auc.tree.SMOTE1)
plot(auc.tree.SMOTE1,ylim=c(0,1),print.thres=T,main=paste('AUC.tree.SMOTE',round(auc.tree.SMOTE1$auc[[1]],3)))



#尝试不同剪枝。这里seed(2)
set.seed(2)
cvtree.SMOTE2<-cv.tree(tree.mod.SMOTE,FUN=prune.tree)
plot(cvtree.SMOTE2$size,cvtree.SMOTE2$dev,type='b')#发现大概在4层
prunetree.SMOTE2<-prune.tree(tree.mod.SMOTE,best=4)
plot(prunetree.SMOTE2)
text(prunetree.SMOTE2,pretty=0,cex=0.6)

prunetree.pred.SMOTE2<-predict(prunetree.SMOTE2,newdata=test.SMOTE,type = 'class')
prunetree.pred2.SMOTE2<-prediction(as.numeric(prunetree.pred.SMOTE2)-1,Ytest01.SMOTE)
perfprunetree.SMOTE2<-performance(prunetree.pred2.SMOTE2,'sens','spec')
#perfprunetree.SMOTE@x.values#speci
#perfprunetree.SMOTE@y.values#sensi
performance(prunetree.pred2.SMOTE2,'auc')@y.values#AUC可以到达0.966!!!woc简直幸福了
summary(prunetree.SMOTE2)

auc.tree.SMOTE2<-roc(Ytest01.SMOTE,as.numeric(prunetree.pred.SMOTE2)-1)
print(auc.tree.SMOTE2)
plot(auc.tree.SMOTE2,ylim=c(0,1),print.thres=T,main=paste('AUC.tree.SMOTE',round(auc.tree.SMOTE2$auc[[1]],3)))

```

整体来看，决策树剪枝选变量还是比较稳健的。可以说明一些问题。
"Ndc80"          "Pramef8"        "Eif1"           "Arl6ip1"        "X1110004F10Rik"
"Orm1"等。重点去看


### 集成、SVM等方法达到了非常优的水平！提升空间非常大

```{r,cache=T}

#5.SVM，不太好解释，但also效果好的一匹
library(e1071)
#wts.SMOTE<-100/table(Ytrain01.SMOTE)
svmfit.SMOTE<-svm(Ytrain01.SMOTE~.,data = train.SMOTE, scale=F,kernel = "radial",probability=T)
            #,class.weights=wts.SMOTE) 
summary(svmfit.SMOTE)
svm.pred.SMOTE<-predict(svmfit.SMOTE,newdata = test.SMOTE)
svm.pred2.SMOTE<-prediction(as.numeric(svm.pred.SMOTE)-1,Ytest01.SMOTE)
perfsvm.SMOTE<-performance(svm.pred2.SMOTE,'sens','spec')
#perfsvm.SMOTE@x.values#speci
#perfsvm.SMOTE@y.values#sensi
performance(svm.pred2.SMOTE,'auc')@y.values#AUC is 1

#6.RF
rf.SMOTE <- randomForest(Ytrain01.SMOTE~., data=train.SMOTE, ntree=100, proximity=TRUE,importance=TRUE) 
sort(importance(rf.SMOTE,type = 1),decreasing = T)[1:20]
varImpPlot(rf.SMOTE)

rf.pred.SMOTE<-predict(rf.SMOTE,newdata = test.SMOTE)
length(rf.pred.SMOTE)
rf.pred2.SMOTE<-prediction(as.numeric(rf.pred.SMOTE)-1,Ytest01.SMOTE)
perfrf.SMOTE<-performance(rf.pred2.SMOTE,'sens','spec')
#perfrf.SMOTE@x.values#speci
#perfrf.SMOTE@y.values#sensi
performance(rf.pred2.SMOTE,'auc')@y.values#AUC 0.99

```



## 方向一的总结：

### SMOTE前
1.SMOTE前的方法中

①SCAD方法得到结果：Calr       Gzma       Ccl5      Hspa5      Snx19 （改变不同的set.seed稳定，只是shrinkage出来的个数不同）

②.tree方法：（但分类结果非常差，所以仅供参考）

③集成方法importance：（但同理，分类结果非常差）

### SMOTE后
2.SMOTE后的方法中：（试过不同SET.SEED看看是不是稳健的）

①SCAD的Ccl5      Calr    Lgals3     Hspa5  Gpatch2l     Axin1      Ipo8      Klf2     Chmp5，
同理，看看不同set.seed是否稳定

②Tree中筛选的：
"Ndc80"    "Pramef8"     "Eif1"   "X1110004F10Rik" "Orm1" （且涵盖顺序）
 这五个基因，可能更加涵盖了某种关系，是先前线性关系训练不到的关系。所以重点去看！！
目前可以确定的是，不同set.seed的剪枝可以保持稳定和阈值稳定 

③集成方法importance：

### Gene Card:
https://www.genecards.org/cgi-bin/carddisp.pl?gene=NDC80


1. NDC80:与染色体分离有关。This gene encodes a component of the NDC80 kinetochore complex. The encoded protein consists of an N-terminal microtubule binding domain and a C-terminal coiled-coiled domain that interacts with other components of the complex. This protein functions to organize and stabilize microtubule-kinetochore interactions and is required for proper chromosome segregation. [provided by RefSeq, Oct 2011]

2.Pramef8 也为蛋白质编码基因

3.Calr：转录调控有关。Calreticulin is a multifunctional protein that acts as a major Ca(2+)-binding (storage) protein in the lumen of the endoplasmic reticulum. It is also found in the nucleus, suggesting that it may have a role in transcription regulation. Calreticulin binds to the synthetic peptide KLGFFKR, which is almost identical to an amino acid sequence in the DNA-binding domain of the superfamily of nuclear receptors. Calreticulin binds to antibodies in certain sera of systemic lupus and Sjogren patients which contain anti-Ro/SSA antibodies, it is highly conserved among species, and it is located in the endoplasmic and sarcoplasmic reticulum where it may bind calcium. The amino terminus of calreticulin interacts with the DNA-binding domain of the glucocorticoid receptor and prevents the receptor from binding to its specific glucocorticoid response element. Calreticulin can inhibit the binding of androgen receptor to its hormone-responsive DNA element and can inhibit androgen receptor and retinoic acid receptor transcriptional activities in vivo, as well as retinoic acid-induced neuronal differentiation. Thus, calreticulin can act as an important modulator of the regulation of gene transcription by nuclear hormone receptors. Systemic lupus erythematosus is associated with increased autoantibody titers against calreticulin but calreticulin is not a Ro/SS-A antigen. Earlier papers referred to calreticulin as an Ro/SS-A antigen but this was later disproven. Increased autoantibody titer against human calreticulin is found in infants with complete congenital heart block of both the IgG and IgM classes. [provided by RefSeq, Jul 2008]

4.RIK gene似乎都搜索不到。是否是长链非编码RNA？较可疑。但老师的说法是这一块我们都先不看了

####

# 方向二：多重假设检验
```{r,cache=T}

#先看正态性
P<-rep(0,ncol(X))
for (i in 1:ncol(X)) {
  P[i]<-shapiro.test(X[,i])$p.value
}
SigP<-P[order(P,decreasing = T)[1:400]]
SigP
hist(X[,2886],breaks = 20)
hist(X[,5814],breaks = 20)

hist(X[,4476],breaks = 20)

#FDR
PFDR<-p.adjust(P,method = 'fdr',n=length(P))
SigPFDR<-PFDR[order(PFDR,decreasing = T)[1:400]]


#distribution????

a<-sum(data[,2:ncol(data)]!=0)
b<-sum(data[,2:ncol(data)]==0)
a
b
a/b
a/(a+b)

rdata<-data[,2:ncol(data)]
aa<-c(rdata[rdata==0],rdata[rdata!=0])
#class(aa)
#summary(aa)
#length(aa)
table(aa[aa!=0])[1:100]
hist(aa,breaks=200,freq = F)#这分布太可怕了
hist(aa[aa!=0],breaks=200,freq = F)#这分布太可怕了

#which.max(aa)
```




## 方向二的总结：




#############

# 总结

当然，以上的所有统计方法都只能做个初步的参考作用，从16000个基因里缩小搜索范围。进一步的研究是需要生物学背景支持的。数据不能完全代替人。

所有模型都是错的。说不定这里找的所有因子和分类也是错的。真正起作用的是在数据集里没有体现出来的某个基因。

# 下一步：

1.(i)解决TSNE问题的标记问题（重要！！！）以及表格标尺的问题,还有不同的set.seed后TSNE也不一样+(ii)解决FPR的原始标记问题+(iii)PCA降维一下看看（这里是为了看看预测问题会不会受到SMOTE的影响。FPR必须为0.TPR越高越好）(iv)不同setseed对shrinkage和决策树、集成方法等的影响。甚至是不同setseed对不同SMOTE后数据的影响。选出来的变量等(v)用SMOTE后importance选出来的变量人工做个LR啊

2. 多重假设检验FDR。先看看是否为正态性.树方法、LASSO方法、和FDR结果筛选变量是否一致。变量一致的时候再检验阈值的稳健性（这一步是检验变量选择和阈值训练的稳定性）

*3.多分类+XGBOOST方法尝试一下(SMOTE前后都要)（目前略）

*4.开始了解不同潜在的基因生物学背景，Gene Card。简单点就好。特别是查RIK（RIK不用查了，其他给老师）

*5.稀疏性/零膨胀问题会不会对logistics产生影响。数据噪音会不会对决策树有影响等（暂时不考虑对方向一的影响，方向二的影响肯定有）

*6.SIS,KF等screening的方法再试一下（方向一可以尝试，先省略）

7.repulicate 文献方法.主要concern的有

（1）使用除了SMOTE方法以外解决非平衡问题的方法（Voronoi diagrams,V-synth合成方法）

（2）解决测序数据噪声。
————Multiplatform single-sample estimates of transcriptional activation
————Bayesian approach to single-cell differential expression analysis

（3）新的聚类方法（提供可视化工具）————sc3: consensus clustering of single-cell rna-seq data。这个可以主要考虑一下

（4）针对零膨胀问题的数据降维（大量dropout导致零膨胀，之前都没有做过处理）————ZIFA: Dimensionality reduction for zero-inflated single-cell gene expression analysis

（5）针对数据本身，可能来自于不同细胞阶段，需要鉴定亚群、阶段（即不再是IID了）————Computational analysis of cell-to-cell heterogeneity in single-cell RnA-sequencing data reveals hidden subpopulations of cells







